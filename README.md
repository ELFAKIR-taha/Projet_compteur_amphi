# Groupe 82

# üéì Manuel Utilisateur - Compteur d'Amphith√©√¢tre

Bienvenue dans le guide d'utilisation de l'application **Compteur d'Amphith√©√¢tre**.
Cet outil a √©t√© con√ßu pour assister les enseignants (toutes disciplines confondues) dans la gestion de leurs cours en amphith√©√¢tre gr√¢ce √† l'analyse d'image.

---

## Installation et Lancement

### 1. Pr√©paration
- **Espace disque :** L'application ne n√©cessite pas d'installation complexe. Cependant, assurez-vous d'avoir environ **1 Go** d'espace libre sur votre ordinateur.
- **Mat√©riel :** Une webcam est n√©cessaire (int√©gr√©e √† l'ordinateur portable ou USB externe).

### 2. D√©marrage
1. T√©l√©chargez et copiez le dossier **CompteurAmphi** sur votre ordinateur.
2. Branchez votre webcam (si vous en utilisez une externe).
   > *Note : Vous pouvez brancher la webcam avant ou apr√®s avoir lanc√© le programme, l'ordre n'a pas d'importance.*
3. Ouvrez le dossier et double-cliquez sur le fichier **`CompteurAmphi.exe`**.

---

## Interface Principale

Une fois l'application lanc√©e, un menu s'ouvre avec 5 options.

![Menu Principal](photos_guide/menu_principal.png)
*Menu d'accueil de l'application*

### Comment lancer une analyse ?

Pour les fonctionnalit√©s **Comptage**, **Sondage** et **Vote**, la proc√©dure est toujours la m√™me :

1. Cliquez sur le bouton de la fonctionnalit√© souhait√©e.
2. Une fen√™tre vous demandera de choisir la source :
    - **Flux vid√©o en direct :** Pour utiliser la webcam.
    - **Importer une image :** Pour analyser une photo d√©j√† enregistr√©e sur votre ordinateur.
3. **Si vous utilisez la vid√©o en direct :** Cadrez l'amphith√©√¢tre, puis appuyez sur la touche **`C`** de votre clavier pour capturer l'image et lancer le calcul.

---

## Les Fonctionnalit√©s en d√©tail

### 1. Comptage üë•
Cette fonction permet de conna√Ætre le nombre total de personnes pr√©sentes dans le champ de la cam√©ra.
- **Usage :** Id√©al pour v√©rifier le taux de pr√©sence.

![Rendu Comptage](photos_guide/comptage.png)
*Exemple de r√©sultat pour le comptage*

### 2. Sondage ‚úã
Cette fonction compte le nombre de personnes qui l√®vent la main par rapport au nombre total de pr√©sents.
- **Usage :** Utile pour poser une question binaire simple (ex: "Qui a fini l'exercice ?").

![Rendu Sondage](photos_guide/sondage.png)
*Exemple de r√©sultat pour le sondage*

### 3. Vote üó≥Ô∏è
Cette fonction est plus pr√©cise et permet de distinguer les choix selon la main lev√©e :
- **Main Droite :** Vote A.
- **Main Gauche :** Vote B.
- **Pas de main lev√©e :** Abstention.

![Rendu Vote](photos_guide/vote.png)
*Exemple de r√©sultat pour le vote*

---

## Suivi et Fermeture

### Historique üìù
Le bouton **Historique** ouvre automatiquement un fichier texte.
- Ce fichier contient les r√©sultats de tous les comptages, sondages et votes effectu√©s pr√©c√©demment (avec la date et l'heure).
- N'h√©sitez pas √† modifier le contenu de ce fichier si vous voulez ajouter des d√©tails, comme par exemple la question du sondage. Le fichier `historique.txt` est sauvegard√© automatiquement dans le dossier CompteurAmphi.

### Quitter ‚ùå
Pour fermer l'application correctement, cliquez simplement sur le bouton **Quitter**.

---

## Astuces pour une meilleure d√©tection

Pour garantir des r√©sultats pr√©cis :
- Assurez-vous que la salle est **suffisamment √©clair√©e**.
- Si possible, placez la cam√©ra un peu **en hauteur** pour bien voir les √©tudiants du fond.
- Demandez aux √©tudiants de lever la main **bien haut** lors des votes.
- Demandez aux √©tudiants de **s'√©carter** le plus possible les uns des autres.

---

# ‚öôÔ∏è Documentation Technique : Compilation et D√©ploiement

Cette partie du document d√©taille la proc√©dure technique pour installer l'environnement de d√©veloppement, g√©rer les d√©pendances et compiler l'application **CompteurAmphi** en un ex√©cutable Windows (`.exe`) autonome.

---

## üìÇ 1. Architecture Requise

Avant toute tentative de compilation, assurez-vous que le dossier du projet respecte strictement cette structure pour que PyInstaller trouve les ressources :

```text
projet/
‚îÇ
‚îú‚îÄ‚îÄ menu.py             # Script principal (Point d'entr√©e)
‚îú‚îÄ‚îÄ yolo_head_test.pt   # Mod√®le IA (T√™tes)
‚îú‚îÄ‚îÄ yolov8x-pose-p6.pt  # Mod√®le IA (Pose)
‚îÇ
‚îî‚îÄ‚îÄ detection/          # Package Python (Logique m√©tier)
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ interface.py
    ‚îú‚îÄ‚îÄ comptage.py
    ‚îú‚îÄ‚îÄ sondage.py
    ‚îî‚îÄ‚îÄ vote.py

```
---
## üõ†Ô∏è 2. Mise en place de l'environnement

### Pr√©requis
- **OS :** Windows 10/11 (64 bits)
- **Python :** Version 3.10 recommand√©e.

### Installation √©tape par √©tape

1.  **Ouvrir un terminal** √† la racine du projet.

2.  **Cr√©er un environnement virtuel (recommand√©) :**
    Ceci isole les biblioth√®ques du projet de votre syst√®me global.
    ```powershell
    python -m venv venv
    venv\Scripts\activate
    ```

3.  **Installer les d√©pendances (Version Optimis√©e CPU) :**
    Pour √©viter que l'ex√©cutable ne p√®se 1.5 Go (√† cause des pilotes graphiques NVIDIA inutiles ici), nous for√ßons l'installation de PyTorch en version CPU.
    
    ```powershell
    # 1. Installer PyTorch CPU
    pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cpu](https://download.pytorch.org/whl/cpu)
    
    # 2. Installer les autres biblioth√®ques
    pip install ultralytics opencv-python pyinstaller
    ```
4.  **V√©rifier l'installation :**
        Lancez cette commande pour confirmer que les biblioth√®ques principales sont bien d√©tect√©es :
    ```        
    powershell
    python -c "import torch; import ultralytics; import cv2; print('Succ√®s : Toutes les biblioth√®ques sont correctement install√©es !')"
    ```        
---

## üì¶ 3. Proc√©dure de Compilation (.exe)

Nous utilisons **PyInstaller** pour g√©n√©rer l'ex√©cutable. La commande inclut sp√©cifiquement les donn√©es n√©cessaires (mod√®les .pt et sous-dossiers).

### La Commande
Ex√©cutez cette commande dans le terminal (environnement virtuel activ√©) :

```powershell
pyinstaller --noconsole --onedir --name="CompteurAmphi" --collect-all ultralytics --add-data "yolo_head_test.pt;." --add-data "yolov8x-pose-p6.pt;." --add-data "detection;detection" --clean --noconfirm menu.py
```
---

# üè∑Ô∏è Documentation Technique : Lab√©lisation du Dataset

Cette partie du document d√©taille la proc√©dure technique pour cr√©er les **annotations** de notre dataset dans les classes suivantes : *personne, bras gauche, bras droit* au format **YOLO**

---

## Objectif
L‚Äôobjectif de notre lab√©lisation est de permettre au mod√®le d‚Äôidentifier :
- La personne enti√®re
- Le bras gauche
- Le bras droit

Ce d√©coupage permet une d√©tection simple mais efficace de la posture des poignets, sans entrer dans la complexit√© d‚Äôun mod√®le de pose estimation complet.

---

## Classes utilis√©es

| ID | Classe |
| :--- | :--- |
| **0** | Bras gauche |
| **1** | Bras droit |
| **2** | Personne |

---

## D√©tails des annotations

### 1. Personne (classe 2)
**Principe :** La bo√Æte doit englober l‚Äôensemble de la personne visible, de la t√™te aux pieds.

- **R√®gles :**
    1. Annoter chaque personne visible dans l‚Äôimage.
    2. Si une partie est coup√©e ‚Üí annoter ce qui est visible.
    3. Ne pas √©tendre la bo√Æte au-del√† du corps.

### 2. Bras gauche (classe 0)
**Principe :** On annote uniquement le poignet gauche anatomique de la personne (pas le bras situ√© √† gauche dans l‚Äôimage !).

- **R√®gles :**
    1. La bo√Æte commence √† hauteur de l‚Äô√©paule gauche.
    2. Elle englobe : le poignet.
    3. Annoter m√™me si partiellement visible.
    4. Si impossible de d√©terminer gauche/droite ‚Üí ne pas annoter.

### 3. Bras droit (classe 1)
**Principe :** M√™me logique que pour le bras gauche, mais pour le bras droit anatomique.

- **R√®gles :**
    1. La bo√Æte englobe uniquement le poignet.
    2. Annoter si la majorit√© du bras est visible.
    3. Si trop ambigu ‚Üí ne pas annoter.

---

## Directives g√©n√©rales

### Distinction gauche vs droite
Toujours bas√©e sur le corps de la personne, jamais sur la perspective de la cam√©ra.
- **Indices utiles :** Orientation du torse, Position des jambes, Direction du visage, Accessoires asym√©triques (montre, sac...).
- En cas d‚Äôambigu√Øt√© totale ‚Üí ne pas annoter le bras.

### Occlusions
- Un bras est annot√© m√™me si tr√®s partielle.
- Une personne est annot√©e m√™me si tr√®s partielle.

### Consistance
- Garder des bo√Ætes coh√©rentes d‚Äôune image √† l‚Äôautre.
- √âviter les bo√Ætes trop larges ou qui englobent de l‚Äôarri√®re-plan inutile.

### Format YOLO
Chaque ligne du fichier .txt d‚Äôannotation contient :
`<class_id> <x_center> <y_center> <width> <height>`

Toutes les valeurs sont normalis√©es entre 0 et 1.

**Exemple :**
*Personne + bras gauche + bras droit*
```text
2 0.50 0.52 0.30 0.70    # Personne
0 0.42 0.55 0.10 0.40    # Bras gauche
1 0.58 0.55 0.10 0.40    # Bras droit
```
 Sch√©ma explicatif (ASCII)
 ```
         ( Personne )
               |
        +----------------+
        |                |
   (Bras gauche)    (Bras droit)
        0                 1

 ```


**Contenu de classes.txt :**

```text
bras_gauche
bras_droit
person
```

*(Les IDs correspondent √† l‚Äôordre : 0, 1, 2)*

### R√©sum√© rapide (TL;DR)

- **0** = Poignet gauche
- **1** = Poignet droit
- **2** = T√™te

**R√®gles cl√©s :**
- **On lab√©lise :**
    * La t√™te ‚Üí **classe 2**
    * Les poignets ‚Üí **classes 0 et 1**
- **Orientation :** La distinction gauche/droite est bas√©e sur le **corps**, pas sur l‚Äôimage.
- **Visibilit√© :** Poignet annot√© m√™me **partiellement**.
- **Doute :** En cas de doute ‚Üí **ne pas annoter**.

---

# üß† Documentation Technique : Fonctionnalit√©s et algorithmes

Cette partie du document d√©taille la proc√©dure technique pour r√©aliser les trois fonctionnalit√©s de l'application, √† savoir le comptage, le sondage et le vote.

---

## 1. Contexte et Objectifs

Le projet vise √† automatiser le comptage d'√©tudiants et l'analyse de votes (main lev√©e) dans un amphith√©√¢tre. L'environnement pr√©sente des contraintes sp√©cifiques : forte densit√©, occultations (√©tudiants cach√©s par les rang√©es) et petits objets (√©tudiants au fond de la salle).
L'application r√©pond √† 3 fonctionnalit√©s :
    1.	Comptage de pr√©sence (Combien de personnes).
    2.	Comptage de mains lev√©es (Interaction globale).
    3.	Vote / Sondage (Distinction Main Gauche / Main Droite / Abstention).


---

## 2. Architecture et Choix des Mod√®les

Le syst√®me repose sur une architecture de Vision par Ordinateur hybride utilisant la biblioth√®que **Ultralytics YOLOv8**. Nous combinons deux approches : la D√©tection d'Objets (Object Detection) et l'Estimation de Pose (Pose Estimation).

### 2.1. Mod√®le de D√©tection (Pr√©sence)
- **Fichier :** `yolo_head_test.pt`
- **Architecture :** YOLOv8 Detect (Fine-tuned).
- **Classe cible :** `T√™te` (Class ID : 0).
- **Justification Technique :** * L'utilisation d'un mod√®le standard "Personne" (COCO) est inefficace car environ 80% du corps des √©tudiants est masqu√© par les tables.
    - La t√™te est la caract√©ristique anatomique la plus visible et constante. Un mod√®le sp√©cialis√© r√©duit drastiquement les faux n√©gatifs dus aux occultations.

### 2.2. Mod√®le d'Estimation de Pose (Analyse de Vote et de sondage)
- **Fichier :** `yolov8x-pose-p6.pt`
- **Architecture :** YOLOv8-Pose.
- **Caract√©ristiques :**
    - **Taille X (Extra Large) :** Privil√©gi√©e pour maximiser la pr√©cision des points cl√©s.
    - **Suffixe P6 :** Mod√®le optimis√© pour les images haute r√©solution (1280px) et la d√©tection de petits objets. C'est crucial pour d√©tecter les poignets des √©tudiants situ√©s au fond de l'amphith√©√¢tre.
    - **Points Cl√©s (Key points) utilis√©s** : √âpaules (Indices 5,6), Coudes (7,8), Poignets (9,10).
- **Justification :** La d√©tection d'objet simple ("Box Main") ne permet pas de savoir √† qui appartient la main ni de distinguer la gauche de la droite avec certitude. L'estimation de pose reconstruit le squelette, validant la structure anatomique.

---

## 3. Strat√©gie d'Annotation et crit√®res : 

Pour assurer la maintenance et le r√©-entra√Ænement futur des mod√®les, les crit√®res d'annotation suivants ont √©t√© appliqu√©s.

### 3.1. Crit√®res pour la D√©tection des T√™tes

- **Zone d'annotation (Bounding Box)** : Du sommet du cr√¢ne jusqu'au menton.

- **Exclusions** :

    - T√™tes visibles √† moins de 50% (ex: √©tudiant cach√© derri√®re la t√™te d'un autre).

    - R√©solution trop faible (< 15*15 pixels) pour √©viter le bruit.

- **Pourquoi pas annoter les mains ?** 
Les mains sont trop mobiles et souvent isol√©es du corps sur l'image. Annoter les t√™tes est plus stable pour la fixation spatiale.


### 3.2. Crit√®res pour la Pose
Nous utilisons la topologie standard COCO Keypoints (17 points), filtr√©e dynamiquement dans le code :
- **Gauche (Left) :** Indices impairs (√âpaule 5, Coude 7, Poignet 9).
- **Droite (Right) :** Indices pairs (√âpaule 6, Coude 8, Poignet 10).

---

## 4. Analyse D√©taill√©e des Algorithmes
### 4.1. Algorithme de Comptage de Pr√©sence
**1√®re fonctionnalit√© :** comptage

Cette fonctionnalit√© permet √† l'utilisateur de choisir sa source (Direct ou Fichier) et visualise les d√©tections en temps r√©el.

**Etape A** : Acquisition de l'image :

Le syst√®me propose deux modes d'entr√©e via une console :
1.	Mode Capture par Webcam :

- Utilise cv2.VideoCapture(0).

- Affiche un flux vid√©o invers√© (cv2.flip) pour un effet miroir naturel.

- L'utilisateur appuie sur 'c‚Äôpour geler l'image (Capture) qui sera analys√©e.

2.	Mode Import un Fichier :

- Ouvre une fen√™tre de dialogue syst√®me via tkinter (filedialog).

- Accepte les formats .jpg, .png.

**√âtape B** : Traitement et Inf√©rence
1.	Chargement du Mod√®le : yolo_head_test.pt.
2.	Inf√©rence : L'image captur√©e ou charg√©e est pass√©e au mod√®le.
3.	Filtrage : On it√®re sur toutes les bo√Ætes d√©tect√©es (r.boxes). On ne conserve que la classe CLASS_ID_HEAD = 0.

### 4.2. Algorithme de sondage et de vote (Gauche / Droite):
Algorithme de Vote et Sondage (HandDetector) utilise une logique avanc√©e pour attribuer correctement une main √† une personne pr√©cise, m√™me dans une foule dense.
**√âtape A** : Strat√©gie de Zoom (Crop)
1.	D√©tection des t√™tes sur l'image globale.
2.	Extraction d'une zone (Crop) agrandie verticalement (x6 la hauteur de la t√™te) pour inclure le buste.
3.	Application du mod√®le Pose sur ce crop.

**√âtape B** : Association stricte par le Nez (Nouveaut√© v1.4) Pour √©viter d'attribuer la main d'un √©tudiant A √† l'√©tudiant B situ√© devant lui :
- Le mod√®le Pose d√©tecte le point cl√© "Nez" (Keypoint 0).

- R√®gle : Un squelette (et donc ses mains) n'est associ√© √† une t√™te que si le nez d√©tect√© se trouve physiquement √† l'int√©rieur de la bo√Æte de la t√™te d√©tect√©e √† l'√©tape A.

- Si le nez est hors de la bo√Æte, le squelette est ignor√©.

**√âtape C** : Validation Anatomique ("Smart Check") Une main est valid√©e si :

1.	Hauteur : Poignet au-dessus de l'√©paule.
2.	Verticalit√© : Angle du bras < 75 degr√©s par rapport √† la verticale.
3.	Confiance : 
Si la d√©tection est floue, elle est accept√©e uniquement si la somme des confiances (Poignet + Coude) > 1.9.

**√âtape D** : Classification du Vote (Par t√™te) Une fois les mains valid√©es et associ√©es √† une t√™te:

- Si main Gauche d√©tect√©e uniquement : Vote 'G'.

- Si main Droite d√©tect√©e uniquement : Vote 'D'.

- Si les deux mains (ou aucune) : Vote 'N ‚Äô (Consid√©r√© comme Abstention ou Neutre).

---

## 5. Sorties, Logs et Preuves de Traitement :
Cette section d√©crit les m√©canismes mis en place pour v√©rifier la validit√© des comptages et assurer la tra√ßabilit√© des r√©sultats g√©n√©r√©s par l'application.

---

### 5.1. Tra√ßabilit√© Administrative (Logs) :
L'application g√©n√®re un fichier journal(.txt) pour conserver l'historique des analyses sans avoir √† stocker les images lourdes.

- Fichier : historique.txt

- Format : Texte brut, horodat√©.

- Exemple de contenu : 25/11/2025 √† 14h30, Il y a 52 √©tudiants

- Utilit√© : Permet une v√©rification a posteriori de l'occupation de la salle, v√©rifier pr√©sence.

---

### 5.2. Interface Utilisateur : 
L'application fournit un retour visuel imm√©diat √† l'utilisateur via une surimpression graphique (Overlay) sur l'image source.
 
Les codes couleurs sont sp√©cifiques √† chaque fonctionnalit√© pour √©viter toute confusion.

**A. Visualisation du Comptage de Pr√©sence**
Utilis√©e pour v√©rifier la localisation des √©tudiants.

- **Bo√Ætes Englobantes (Bounding Boxes)** :
    - Couleur : Verte (0, 255, 0).

    - R√¥le : D√©limite la zone identifi√©e comme "T√™te". Confirme que le mod√®le ne d√©tecte pas d'objets inanim√©s.

- **√âtiquette** : Mention "Etudiant" affich√©e au-dessus de chaque bo√Æte.

- **Compteur Global** : Affichage du total en Bleu (255, 0, 0) en haut √† gauche de l'image.

**B. Visualisation du Vote et Sondage** :

  *1.  Mode SONDAGE (Pour / Contre) :*

Ce mode mesure une adh√©sion. Il ignore visuellement les abstentionnistes pour mettre en √©vidence les participants actifs.

- VERT (0, 255, 0) : POUR.

    - D√©clencheur : D√©tection d'une seule main lev√©e.

    - ROUGE (0, 0, 255) : CONTRE.

- D√©clencheur :soit aucune main lev√©e soit deux mains lev√©es.

    *2.  Mode "VOTE" (G / D / Abstention)*
Ce mode analyse la r√©partition compl√®te de l'auditoire, incluant les passifs.
- VERT (0, 255, 0) : Vote Droite (D).

    - D√©clencheur : Main Droite lev√©e.

- BLEU (255, 0, 0) : Vote Gauche (G).

    - D√©clencheur : Main Gauche lev√©e.

- NOIR (0, 0, 0) : Abstention.

    - D√©clencheur : Aucune main d√©tect√©e ou vote invalide (2 mains).

    - Note : Pour la lisibilit√© du pourcentage "Abstention" sur le bandeau noir en haut de l'image, le texte est affich√© en Gris Clair (200, 200, 200).

---

## 6.PROTOCOLE D'√âVALUATION ET OPTIMISATION :

Afin de justifier scientifiquement les valeurs des param√®tres utilis√©s dans le code, des scripts d'√©valuation d√©di√©s ont √©t√© d√©velopp√©s.

 ### 6.1 Objectif des scripts d'√©valuation : 
Ces scripts ne servent pas √† l'ex√©cution de l'application, mais √† la mesure de sa performance. Ils permettent de comparer les r√©sultats de l'algorithme contre une Dataset annot√©e.

 ### 6.2 M√©triques calcul√©es:
L'√©valuation repose sur des indicateurs standards en vision par ordinateur :

- Pr√©cision : Le mod√®le d√©tecte-t-il correctement sans inventer d'objets (Faux Positifs)

- Rappel : Le mod√®le parvient-il √† trouver tous les objets pr√©sents dans l'image sans en oublier (Faux N√©gatifs)

- F1-Score : Moyenne harmonique permettant de juger l'√©quilibre entre la d√©tection de tous les √©tudiants et la fiabilit√© de chaque d√©tection.
---

## 7. SOURCES ET CARACT√âRISTIQUES DES MOD√àLES (SOURCES √Ä L'APPUI) :
Cette section d√©taille l'origine des mod√®les pour garantir la transparence technique et permettre de retrouver les performances attendues.
  ### 7.1. Framework de Base : Ultralytics YOLOv8 :
Le projet repose enti√®rement sur le Framework Ultralytics YOLOv8.

- **Source officielle** : GitHub Ultralytics (https://github.com/ultralytics/ultralytics).

- **Papier de r√©f√©rence** : Jocher, G., Chaurasia, A., & Qiu, J. (2023). YOLO by Ultralytics.

- C'est actuellement l'architecture offrant le meilleur compromis Vitesse/Pr√©cision et une API Python native facilitant l'int√©gration hybride (Detect + Pose).

 ### 7.2. Mod√®le de D√©tection : yolo_head_test.pt 
Ce mod√®le est un mod√®le externe pr√©-entra√Æn√©, r√©cup√©r√© pr√™t √† l'emploi ("Out-of-the-box") pour r√©pondre √† la probl√©matique sp√©cifique de l'amphith√©√¢tre.

- **Type** : Mod√®le communautaire sp√©cialis√© (Custom Trained Model).

- **Classe cible** : T√™te (Head).

- **Origine technique** : L'utilisation de ce mod√®le, √©prouv√© sur des sc√©narios de foule (CrowdHuman dataset), est une r√©ponse technique aux probl√®mes de densit√©. Il surclasse nettement les mod√®les g√©n√©ralistes lorsqu'il s'agit de distinguer des t√™tes coll√©es ou partiellement masqu√©es.

- **Avantage du choix** : L'utilisation d'un mod√®le existant a permis d'√©conomiser la phase co√ªteuse de constitution de dataset et d'entra√Ænement ou fine-tuning, garantissant une mise en production rapide avec des r√©sultats fiables d√®s le d√©part.
  ### 7.3. Mod√®le d'Estimation de Pose : yolov8x-pose-p6.pt 
Ce mod√®le est un mod√®le pr√©-entra√Æn√© officiel fourni par Ultralytics.

- **Source des poids** : D√©p√¥t officiel Ultralytics Assets.

- **Dataset d'origine** : COCO Keypoints (Common Objects in Context). Ce dataset contient plus de 200 000 images annot√©es avec 17 points cl√©s humains. C'est ce qui garantit que le mod√®le connait la diff√©rence anatomique entre un bras gauche et un bras droit.

- **Sp√©cificit√© "P6" (High-Res)** :

    - Les mod√®les standards (P5) ont 3 couches de sortie (stride 8, 16, 32).

    - Le mod√®le P6 ajoute une 4√®me couche (stride 64) et est entra√Æn√© en 1280 pixels.

    - Impact Projet : C'est cette caract√©ristique technique pr√©cise qui permet de voir les mains au fond de l'amphi. Sans le P6, les √©tudiants du fond seraient ignor√©s.

---

# üìà Documentation Technique : Scripts d'√âvaluation
 
Cette partie du document vise √† expliquer la logique d'√©valuation et les m√©triques utilis√©es par les trois scripts principaux (`evaluer_t√™te.py`, `evaluer_sondage.py`, `evaluer_vote.py`).

---

## 1. Principes Communs d'√âvaluation

Tous les scripts s'appuient sur les principes suivants :

1.  **Dossiers standardis√©s** : Les r√©sultats sont enregistr√©s dans le dossier `evaluation/resultats/`. Les pr√©dictions d√©taill√©es (format YOLO) sont export√©es dans `evaluation/predictions_*/`.
2.  **M√©triques de classification** : Les performances sont mesur√©es √† l'aide de la **Pr√©cision**, du **Rappel** et du **F1-Score**, calcul√©s √† partir des Vrais Positifs (TP), Faux Positifs (FP) et Faux N√©gatifs (FN).

---

## 2. `evaluer_t√™te.py` : √âvaluation du Comptage (D√©tection d'Objet)

Ce script √©value la performance du mod√®le de d√©tection d'objets (YOLO Head) √† localiser et compter les personnes.

### Logique et Crit√®res :

- **But** : Mesurer l'exactitude des Bounding Boxes (BB) des t√™tes.
- **Classe Cibl√©e (Ground Truth)** : La **Classe `2`** (T√™tes) du fichier de labels.
- **Source de Pr√©diction** : Les BBs de t√™tes g√©n√©r√©es par `CompteurAmphi.compter()`.
- **Crit√®re de Matching (TP)** : Utilisation de l'**IoU (Intersection over Union)**.
    * Un match est valid√© si l'**IoU est sup√©rieur ou √©gal √† 0.5**.
- **Conclusion** : Ce script teste si une personne est physiquement d√©tect√©e au bon endroit, ind√©pendamment de ses mains.

---

## 3. `evaluer_sondage.py` : √âvaluation de la D√©tection de Mains (G√©n√©rique)

Ce script √©value la capacit√© du syst√®me √† d√©tecter **toute main lev√©e** (classes 0 et 1), sans tenir compte de la classification finale "POUR" ou "CONTRE". Il se concentre sur la **pr√©cision spatiale** des keypoints du poignet.

### Logique et Crit√®res :

- **But** : Mesurer la performance de la cha√Æne de d√©tection de mains (Pose Estimation) en tant que localisateur de poignet.
- **Classes Cibl√©es (Ground Truth)** : Les **Classes `0` et `1`** (Mains) du fichier de labels.
- **Source de Pr√©diction** : La liste aplatie de tous les poignets d√©tect√©s dans `head['hands']`.
- **Localisation** : Le point de r√©f√©rence est le **Poignet** (`p['x'], p['y']`).
- **Crit√®re de Matching (TP)** : Utilisation de la **Distance Euclidienne**.
    * **Seuil Dynamique** : Le rayon de tol√©rance est adapt√© √† la taille de la personne (`dynamic_threshold = pred['head_h'] * MATCHING_RADIUS_RATIO`). Cela rend l'√©valuation juste, car la distance en pixels pour une petite t√™te (loin) est plus petite.
- **Conclusion** : Ce script teste le Rappel (si toutes les mains sont trouv√©es) et la Pr√©cision de la localisation du keypoint du poignet.

---

## 4. `evaluer_vote.py` : √âvaluation de la Classification de Vote (Gauche/Droite)

Ce script est le plus complet. Il √©value si le syst√®me d√©tecte correctement une main **et** s'il l'associe au bon c√¥t√© (Gauche ou Droite).

### Logique et Crit√®res :

- **But** : Mesurer la performance de la **classification de c√¥t√©** (Gauche vs Droite).
* **Classes Cibl√©es (Ground Truth)** : Les **Classes `0` (Gauche)** et **`1` (Droite)** du fichier de labels.
- **Source de Pr√©diction** : Liste aplatie de tous les poignets d√©tect√©s dans `head['hands']`.
- **Crit√®re de Matching (TP)** : Double v√©rification n√©cessaire :
    1.  **Localisation Spatiale** : La Distance Euclidienne doit √™tre inf√©rieure au Seuil Dynamique (`threshold = pred['head_h'] * MATCHING_RADIUS_RATIO`).
    2.  **Validation de Classe** : Le c√¥t√© pr√©dit (`p['side']`) doit correspondre √† la classe GT.
- **M√©triques D√©taill√©es** : Les r√©sultats sont ventil√©s par classe (Gauche vs Droite) pour identifier si le syst√®me est plus performant sur un c√¥t√© que l'autre.

| Script | Cible | M√©trique Spatiale | Seuil | S√©mantique (G/D) |
| :--- | :--- | :--- | :--- | :--- |
| **`evaluer_t√™te.py`** | T√™te (BB) | IoU | ‚â• 0.5 | Non (Classe 2) |
| **`evaluer_sondage.py`** | Main (Poignet) | Distance Euclidienne | Dynamique (`head_h` * 1.0) | Non (D√©tection pure) |
| **`evaluer_vote.py`** | Main (Poignet) | Distance Euclidienne | Dynamique (`head_h` * 1.0) | **Oui** (N√©cessite correspondance G/D) |

---

# üíæ Documentation Technique : Sauvegarde des r√©sultats

Cette partie du document d√©taille la proc√©dure technique pour mettre en place la **sauvegarde** des r√©sultats des fonctionnalit√©s dans un fichier texte.
---

## 1. Objectif
Le but de cette m√©thode est de **conserver un historique des r√©sultats** dans un fichier texte. Chaque ex√©cution ajoute une ligne avec la date, l‚Äôheure, le nombre d‚Äô√©tudiants et le pourcentage de personnes levant la main.

---

## 2. √âtapes d√©taill√©es

### 2.1 V√©rification et cr√©ation du fichier
On v√©rifie si le fichier `historique.txt` existe.
S‚Äôil n‚Äôexiste pas, on le cr√©e vide :

```python
if not os.path.exists(fichier):
    with open(fichier, "w", encoding="utf-8") as f:
        f.write("")
```

### 2.2 R√©cup√©ration de la date et heure
On attribue une valeur √† la variable `date_heure` :

```python
date_heure = datetime.now().strftime("%d/%m/%y √† %Hh%M")
```

### 2.3 Pr√©paration de la ligne √† √©crire
√Ä la variable `ligne`, on affecte la phrase que l'on souhaite √©crire dans le fichier texte, en y int√©grant les valeurs √† enregistrer :

```python
ligne = f"[C]: {date_heure}, Il y a {self.count} √©tudiants\n"
```

### 2.4 √âcrire dans le fichier
On utilise le mode `"a"` (*append*) pour ne pas √©craser l'historique :

```python
with open(fichier, "a", encoding="utf-8") as f:
    f.write(ligne)
```
---

## 3. Sondage et vote
On effectue la m√™me chose pour le vote et le sondage : on modifie seulement la phrase √† enregistrer et les valeurs √©crites.
